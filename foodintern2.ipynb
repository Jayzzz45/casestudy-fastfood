{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.graphics.mosaicplot import mosaic\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#looking into the dataframe\n",
    "\n",
    "mcdonalds = pd.read_csv(\"mcdonalds.csv\") \n",
    "print(mcdonalds.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mcdonalds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mcdonalds.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcdonalds.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting  'Yes'/'No' responses to binary 1/0\n",
    "MD_x = mcdonalds.iloc[:, :11].map(lambda x: 1 if x == \"Yes\" else 0)\n",
    "col_means = MD_x.mean().round(2)\n",
    "print(col_means)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# dataframe to calculate pca,std and cumproportion\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "MD_pca = pca.fit_transform(MD_x)\n",
    "\n",
    "pcasum_df = pd.DataFrame({\n",
    "    \"Principal Component\": range(1, len(pca.explained_variance_) + 1),\n",
    "    \"Standard Deviation\": pca.explained_variance_,\n",
    "    \"Proportion of Variance\": pca.explained_variance_ratio_,\n",
    "})\n",
    "\n",
    "pcasum_df[\"Cumulative Proportion\"] = pcasum_df[\"Proportion of Variance\"].cumsum()\n",
    "\n",
    "pcasum_df = pcasum_df[['Principal Component', 'Standard Deviation',  'Cumulative Proportion','Proportion of Variance',]]\n",
    "\n",
    "print(\"Pca Summary:\")\n",
    "print(pcasum_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pca of various categories decomposed together\n",
    "decomposed_df = pd.DataFrame(pca.components_.T, columns=[f'PC{i+1}' for i in range(pca.n_components_)])\n",
    "\n",
    "decomposed_df.index = MD_x.columns\n",
    "\n",
    "with pd.option_context('display.float_format', '{:.2f}'.format):\n",
    "    print(\"PCA decomposed:\")\n",
    "    print(decomposed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the PCA model and obtaining the  scores and scatter_map\n",
    "pca.fit(MD_x)\n",
    "scores = pca.transform(MD_x)   \n",
    "scatter_map = pca.components_.T     \n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot the observations on the first two principal components\n",
    "plt.scatter(scores[:, 0], scores[:, 1], color='grey', alpha=0.5, label='Observations')\n",
    "for i in range(scatter_map.shape[0]):\n",
    "    plt.arrow(0, 0, scatter_map[i, 0], scatter_map[i, 1], color='red', alpha=0.7, head_width=0.05)\n",
    "    plt.text(scatter_map[i, 0] * 1.15, scatter_map[i, 1] * 1.15, mcdonalds.columns[i], color='red', \n",
    "             ha='center', va='center')\n",
    "\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.axhline(0, color='grey', linestyle='--', linewidth=0.5)\n",
    "plt.axvline(0, color='grey', linestyle='--', linewidth=0.5)\n",
    "plt.title('PCA of Fast Food mcdonalds data  Set')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding out the best K forr suitable clusters\n",
    "k_range = range(2, 9)\n",
    "inertias = []\n",
    "silhouette_scores = []\n",
    "k_result = []\n",
    "\n",
    "for k in k_range:\n",
    "    model = KMeans(n_clusters=k, n_init=10, random_state=0)\n",
    "    labels = model.fit_predict(decomposed_df)\n",
    "    inertia = model.inertia_\n",
    "    silhouette = silhouette_score(decomposed_df, labels)\n",
    "\n",
    "    inertias.append(inertia)\n",
    "    silhouette_scores.append(silhouette)\n",
    "    k_result.append(labels)\n",
    "\n",
    "\n",
    "plt.bar(k_range, inertias)\n",
    "plt.grid(False)\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('sum of within cluster distances')\n",
    "plt.title('Elbow Method for Optimal k')\n",
    "plt.xticks(k_range)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#box plot for global stability of k_means \n",
    "boot_n = 200\n",
    "ARI_scores = []\n",
    "\n",
    "for label in k_result :\n",
    "    bootstrap_samples = [np.random.choice(label, size=len(label), replace=True) for _ in range(boot_n)]\n",
    "    ari_boot = [adjusted_rand_score(label, bootstrap_sample) + 0.01 for bootstrap_sample in bootstrap_samples]\n",
    "    ARI_scores.append(ari_boot)\n",
    "plt.boxplot(ARI_scores, tick_labels=range(2, 9))\n",
    "plt.title('Adjusted Rand Index Distribution')\n",
    "plt.xlabel('Number of Segments')\n",
    "plt.ylabel('Adjusted Rand Index')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated configuration for histogram plots\n",
    "similarity_range = (0, 0.9) \n",
    "bin_count = 15                \n",
    "max_hist_frequency = 150      \n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "# Generating  histograms for each clustera\n",
    "def plot_similarity_histograms(data_set, model_dict, axes_array, bins, range_values, max_freq):\n",
    "    for cluster_id in range(1, 5):\n",
    "        \n",
    "        predicted_labels = model_dict[str(cluster_id)].predict(data_set)\n",
    "        min_distances = model_dict[str(cluster_id)].transform(data_set).min(axis=1)\n",
    "        \n",
    "        # Determining the  subplot position\n",
    "        row_idx = (cluster_id - 1) // 2\n",
    "        col_idx = (cluster_id - 1) % 2\n",
    "        ax = axes_array[row_idx, col_idx]\n",
    "        \n",
    "        ax.hist(min_distances, bins=bins, range=range_values, color='skyblue', edgecolor='black')\n",
    "        ax.set_xlabel('Similarity')\n",
    "        ax.set_ylabel('Frequency')\n",
    "        ax.set_title(f'Cluster {cluster_id}')\n",
    "\n",
    "        ax.set_xlim(range_values)\n",
    "        ax.set_ylim(0, max_freq)\n",
    "        ax.set_xticks([0, 0.15, 0.3, 0.45, 0.6, 0.75, 0.9])  # Adjusted ticks for the new range\n",
    "\n",
    "plot_similarity_histograms(MD_x, MD_km28, axes, bin_count, similarity_range, max_hist_frequency)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated segment range and Segment level stability across solutions\n",
    "n_clusters_range = range(2, 9)\n",
    "stability_scores = []\n",
    "\n",
    "# Calculating stability for each clustering solutions\n",
    "for n_clusters in n_clusters_range:\n",
    "    cluster_labels = MD_km28[str(n_clusters)].predict(MD_x)  \n",
    "    stability_scores.append(cluster_labels)\n",
    "\n",
    "plt.figure(figsize=(10, 6)) \n",
    "\n",
    "for idx, n_clusters in enumerate(n_clusters_range):\n",
    "    stability_values = [\n",
    "        np.mean(stability_scores[idx] == cluster_label_set)\n",
    "        for cluster_label_set in stability_scores\n",
    "    ]\n",
    "    plt.plot(\n",
    "        n_clusters_range, stability_values, \n",
    "        marker='D', linestyle='--', linewidth=1.5, \n",
    "        label=f'Clusters: {n_clusters}'\n",
    "    )\n",
    "\n",
    "plt.xlabel('Number of Clusters', fontsize=12)\n",
    "plt.ylabel('Average Stability Score', fontsize=12)\n",
    "plt.title('Cluster Stability Analysis (CSA) Across Solutions', fontsize=14, fontweight='bold')\n",
    "plt.xticks(n_clusters_range, fontsize=10)\n",
    "plt.legend(title=\"Cluster Solutions\")\n",
    "plt.grid(color='gray', linestyle=':', linewidth=0.5)  \n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the  segment level stability within solutions and initialize result storage \n",
    "segment_ids = [\"1\", \"2\", \"3\", \"4\"]\n",
    "cluster_labels = {}\n",
    "cluster_distances = {}\n",
    "\n",
    "# Compute cluster labels and distances for each segment\n",
    "def compute_cluster_metrics(data, segment_list, model_dict):\n",
    "    labels, distances = {}, {}\n",
    "    for seg in segment_list:\n",
    "        labels[seg] = model_dict[seg].predict(data)\n",
    "        distances[seg] = model_dict[seg].transform(data).min(axis=1)\n",
    "    return labels, distances\n",
    "\n",
    "# Executing the  clustering metrics computation\n",
    "cluster_labels, cluster_distances = compute_cluster_metrics(MD_x, segment_ids, MD_km28)\n",
    "\n",
    "def calculate_stability(distances_dict):\n",
    "    stability_values = []\n",
    "    for distances in distances_dict.values():\n",
    "        normalized_distances = distances / np.max(distances)\n",
    "        stability_values.append(normalized_distances)\n",
    "    return stability_values\n",
    "\n",
    "segment_stability_scores = calculate_stability(cluster_distances)\n",
    "def plot_stability_scores(stability_scores, segments):\n",
    "    plt.boxplot(stability_scores, whis=1.5)\n",
    "    plt.xlabel(\"Segment Number\")\n",
    "    plt.ylabel(\"Stability Score\")\n",
    "    plt.xticks(range(1, len(segments) + 1), segments)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.title(\"Segment Stability Across Solutions\")\n",
    "    plt.show()\n",
    "\n",
    "plot_stability_scores(segment_stability_scores, segment_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Seed and configuration\n",
    "np.random.seed(1234)\n",
    "k_values = range(2, 9)\n",
    "MD_m28 = []\n",
    "\n",
    "# Model fitting and metric calculations\n",
    "for k in k_values:\n",
    "    model = KMeans(n_clusters=k, random_state=1234)\n",
    "    model.fit(MD_x)  \n",
    "    \n",
    "    iter_val = model.n_iter_\n",
    "    converged = model.n_init == 1 or model.inertia_ < 1e-10\n",
    "    k_val = k\n",
    "    k0_val = k\n",
    "    log_likelihood = -model.inertia_\n",
    "    n_samples, _ = MD_x.shape\n",
    "    \n",
    "    # Information Criteria calculations\n",
    "    aic = -2 * log_likelihood + 2 * k\n",
    "    bic = -2 * log_likelihood + np.log(n_samples) * k\n",
    "\n",
    "    # Entropy and ICL (Integrated Complete Likelihood)\n",
    "    labels = model.labels_\n",
    "    counts = np.bincount(labels)\n",
    "    probs = counts / float(counts.sum())\n",
    "    class_entropy = entropy(probs)\n",
    "    icl = bic - class_entropy\n",
    "    \n",
    "    MD_m28.append((iter_val, converged, k_val, k0_val, log_likelihood, aic, bic, icl))\n",
    "\n",
    "\n",
    "MD_m28 = pd.DataFrame(MD_m28, columns=['iter', 'converged', 'k', 'k0', 'logLik', 'AIC', 'BIC', 'ICL'])\n",
    "\n",
    "print(MD_m28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_segments = MD_m28[\"k\"]\n",
    "AIC_values = MD_m28[\"AIC\"]\n",
    "BIC_values = MD_m28[\"BIC\"]\n",
    "ICL_values = MD_m28[\"ICL\"]\n",
    "\n",
    "plt.plot(num_segments, AIC_values, marker='o', label='AIC')\n",
    "plt.plot(num_segments, BIC_values, marker='o', label='BIC')\n",
    "plt.plot(num_segments, ICL_values, marker='o', label='ICL')\n",
    "\n",
    "plt.xlabel('Number of Segments')\n",
    "plt.ylabel('Value of Information Criteria')\n",
    "plt.title('Information Criteria (AIC, BIC, ICL)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "\n",
    "num_clusters = 4\n",
    "\n",
    "kmeans_model = KMeans(n_clusters=num_clusters, random_state=1234)\n",
    "kmeans_model.fit(MD_x)\n",
    "kmeans_assignments = kmeans_model.predict(MD_x)\n",
    "\n",
    "# Fitting the  Gaussian Mixture Model and predicting  clusters\n",
    "gmm_model = GaussianMixture(n_components=num_clusters, random_state=1234)\n",
    "gmm_model.fit(MD_x)\n",
    "gmm_assignments = gmm_model.predict(MD_x)\n",
    "\n",
    "cluster_results = pd.DataFrame({'KMeans': kmeans_assignments, 'GMM': gmm_assignments})\n",
    "\n",
    "filtered_data = MD_x[cluster_results['GMM'] == 3]\n",
    "\n",
    "filtered_kmeans_model = KMeans(n_clusters=num_clusters, random_state=1234)\n",
    "filtered_kmeans_model.fit(filtered_data)\n",
    "filtered_kmeans_assignments = filtered_kmeans_model.predict(filtered_data)\n",
    "\n",
    "filtered_results = pd.DataFrame({'KMeans': filtered_kmeans_assignments, 'GMM': 3})\n",
    "\n",
    "# Cross-tabulation between KMeans and GMM\n",
    "cross_tab_1 = pd.crosstab(cluster_results['KMeans'], cluster_results['GMM'])\n",
    "cross_tab_2 = pd.crosstab(cluster_results['KMeans'], filtered_results['KMeans'])\n",
    "\n",
    "print(\"Cross-tabulation Results (KMeans vs. GMM):\")\n",
    "print(cross_tab_1)\n",
    "\n",
    "print(\"\\nCross-tabulation Results (KMeans vs. KMeans for filtered data):\")\n",
    "print(cross_tab_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_ma = GaussianMixture(n_components=4)\n",
    "gmm_ma.fit(MD_x)\n",
    "\n",
    "log_likelihood_ma = gmm_ma.score(MD_x)\n",
    "\n",
    "gmm_m = GaussianMixture(n_components=4)\n",
    "gmm_m.fit(MD_x)\n",
    "\n",
    "log_likelihood_m = gmm_m.score(MD_x)\n",
    "\n",
    "print(\"Log-likelihood for MD_x.ma:\", log_likelihood_ma)\n",
    "print(\"Log-likelihood for MD_x.m:\", log_likelihood_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm  \n",
    "\n",
    "# Extracting the KMeans model for segment 4\n",
    "kmeans_model_segment4 = MD_km28['4']\n",
    "\n",
    "# Get labels assigned by the KMeans model\n",
    "segment_labels = kmeans_model_segment4.labels_\n",
    "\n",
    "mean_values_per_segment = MD_x.groupby(segment_labels).mean()\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 6))\n",
    "\n",
    "color_palette = cm.viridis  \n",
    "\n",
    "# Looping through each segment and plot the mean values\n",
    "for segment_index in range(mean_values_per_segment.shape[0]):\n",
    "    num_variables = mean_values_per_segment.shape[1]\n",
    "    \n",
    "    for variable_index in range(num_variables):\n",
    "        color = color_palette(variable_index / num_variables)  \n",
    "        axes[segment_index // 2, segment_index % 2].barh(variable_index, mean_values_per_segment.iloc[segment_index, variable_index], color=color)\n",
    "\n",
    "    axes[segment_index // 2, segment_index % 2].set_title(f'Segment {segment_index + 1}')\n",
    "    axes[segment_index // 2, segment_index % 2].set(ylabel='Variable', xlabel='Mean Value')\n",
    "    axes[segment_index // 2, segment_index % 2].set_yticks(range(num_variables))\n",
    "    axes[segment_index // 2, segment_index % 2].set_yticklabels(MD_x.columns)\n",
    "\n",
    "\n",
    "fig.suptitle('Mean Profiles of Segments')\n",
    "\n",
    "fig.tight_layout(rect=[0, 0, 0.85, 1])  \n",
    "\n",
    "legend_handles = [plt.Rectangle((0, 0), 1, 1, color=color_palette(i / num_variables)) for i in range(num_variables)]\n",
    "plt.legend(legend_handles, MD_x.columns, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kmeans = KMeans(n_clusters=4)\n",
    "kmeans.fit(MD_x)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "MD_pca = pca.fit_transform(MD_x)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(MD_pca[:, 0], MD_pca[:, 1])\n",
    "ax.set_xlabel('principal component 1')\n",
    "ax.set_ylabel('principal component 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_4 = KMeans(n_clusters=4, random_state=0)\n",
    "k_4.fit(df_decomposed)\n",
    "l_4 = k_4.labels_\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "markers = ['o', 's', '^', 'd']\n",
    "edge_colors = ['darkblue', 'orange', 'grey', 'red']\n",
    "\n",
    "for i in range(4):\n",
    "    temp = df_decomposed[l_4 == i]\n",
    "    plt.scatter(\n",
    "        temp['yummy'],\n",
    "        temp['convenient'],\n",
    "        label=i,\n",
    "        edgecolor=edge_colors[i],\n",
    "        marker=markers[i],\n",
    "        facecolor='none',\n",
    "        alpha=0.5\n",
    "    )\n",
    "\n",
    "scale = 1.7\n",
    "\n",
    "texts = []\n",
    "for i, j in enumerate(df_decomposed.columns):\n",
    "    text = plt.text(\n",
    "        p.components_[0, i] * scale,\n",
    "        p.components_[1, i] * scale,\n",
    "        j,\n",
    "        color='red',\n",
    "        fontsize=12,\n",
    "        ha='center',\n",
    "        va='bottom',\n",
    "        stretch=\"expanded\"\n",
    "    )\n",
    "    texts.append(text)\n",
    "    plt.arrow(0, 0, p.components_[0, i] * scale, p.components_[1, i] * scale, color='red')\n",
    "    plt.annotate(\n",
    "        '', xytext=(0, 0),\n",
    "        xy=(p.components_[0, i] * scale, p.components_[1, i] * scale),\n",
    "        arrowprops=dict(\n",
    "            arrowstyle=\"->\",\n",
    "            color='red'\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "plt.scatter(\n",
    "    p.components_[0, :] * scale,\n",
    "    p.components_[1, :] * scale,\n",
    "    s=0.5,\n",
    "    color='red'\n",
    ")\n",
    "\n",
    "plt.grid(False)\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.title('Principal Component Axes')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a mapping of string values to numeric codes\n",
    "sentiment_mapping = {\n",
    "    'I HATE IT!-5': -5,\n",
    "    '-4': -4,\n",
    "    '-3': -3,\n",
    "    '-2': -2,\n",
    "    '-1': -1,\n",
    "    '0': 0,\n",
    "    '1': 1,\n",
    "    '2': 2,\n",
    "    '3': 3,\n",
    "    '4': 4,\n",
    "    'I LOVE IT!+5': 5\n",
    "}\n",
    "\n",
    "# Map the 'Like' column to numeric values\n",
    "mcdonalds['Like.n'] = mcdonalds['Like'].map(sentiment_mapping)\n",
    "\n",
    "like_n_counts = mcdonalds['Like.n'].value_counts().reset_index()\n",
    "like_n_counts.columns = ['Numeric Value', 'Count']\n",
    "\n",
    "print(\"Numeric Value | Count\")\n",
    "print(\"-\" * 20)\n",
    "for index, row in like_n_counts.iterrows():\n",
    "    print(f\"{row['Numeric Value']: <15} | {row['Count']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from statsmodels.graphics.mosaicplot import mosaic\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Label encoding for categorical columns - Converting 11 columns with yes/no\n",
    "def encode_labels(column):\n",
    "    mcdonalds[column] = LabelEncoder().fit_transform(mcdonalds[column])\n",
    "    return mcdonalds\n",
    "\n",
    "# List of categorical columns to encode\n",
    "categorical_columns = [\n",
    "    'yummy', 'convenient', 'spicy', 'fattening', 'greasy',\n",
    "    'fast', 'cheap', 'tasty', 'expensive', 'healthy', 'disgusting'\n",
    "]\n",
    "\n",
    "for column in categorical_columns:\n",
    "    encode_labels(column)\n",
    "\n",
    "selected_mcdonalds = mcdonalds.loc[:, categorical_columns]\n",
    "\n",
    "# Fitting KMeans clustering\n",
    "kmeans_model = KMeans(n_clusters=4, init='k-means++', random_state=0).fit(selected_mcdonalds)\n",
    "mcdonalds['cluster_label'] = kmeans_model.labels_\n",
    "\n",
    "unique_like_categories = mcdonalds['Like'].unique()\n",
    "\n",
    "crosstab_result = pd.crosstab(mcdonalds['cluster_label'], mcdonalds['Like'])\n",
    "\n",
    "crosstab_result = crosstab_result[unique_like_categories]\n",
    "\n",
    "# Plotting\n",
    "plt.rcParams['figure.figsize'] = (7, 5)\n",
    "mosaic(crosstab_result.stack())\n",
    "plt.title('Mosaic Plot of Clusters vs Like Values')\n",
    "plt.xlabel('Clusters')\n",
    "plt.ylabel('Like Values')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross tabulation of segment and gender\n",
    "MD_k4=MD_km28['4']\n",
    "k4 = MD_k4.labels_\n",
    "\n",
    "ct = pd.crosstab(k4, mcdonalds['Gender'])\n",
    "ct\n",
    "mosaic(ct.stack(),gap=0.01)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#box and whisker plot for age and segment\n",
    "data = {\n",
    "    'segment': labels,\n",
    "    'Age': mcdonalds.Age\n",
    "}\n",
    "dff = pd.DataFrame(data)\n",
    "\n",
    "plt.figure(figsize=(9, 5))\n",
    "sns.boxplot(x='segment', y='Age', data=dff)\n",
    "plt.xlabel('Segment')\n",
    "plt.ylabel('Age')\n",
    "plt.title('Box-and-Whisker Plot of Age by Segment')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouping \n",
    "mcdonalds['VisitFrequency'] = LabelEncoder().fit_transform(mcdonalds['VisitFrequency'])\n",
    "visit = mcdonalds.groupby('cluster_label')['VisitFrequency'].mean()\n",
    "visit = visit.to_frame().reset_index()\n",
    "visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcdonalds['Like'] = LabelEncoder().fit_transform(mcdonalds['Like'])\n",
    "Like = mcdonalds.groupby('cluster_label')['Like'].mean()\n",
    "Like = Like.to_frame().reset_index()\n",
    "Like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcdonalds['Gender'] = LabelEncoder().fit_transform(mcdonalds['Gender'])\n",
    "Gender = mcdonalds.groupby('cluster_label')['Gender'].mean()\n",
    "Gender = Gender.to_frame().reset_index()\n",
    "Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter Plot for Segment Evaluation\n",
    "mcdonalds['VisitFrequency'] = LabelEncoder().fit_transform(mcdonalds['VisitFrequency'])\n",
    "visit = mcdonalds.groupby('cluster_label')['VisitFrequency'].mean().reset_index()\n",
    "mcdonalds['Like'] = LabelEncoder().fit_transform(mcdonalds['Like'])\n",
    "Like = mcdonalds.groupby('cluster_label')['Like'].mean().reset_index()\n",
    "mcdonalds['Gender'] = LabelEncoder().fit_transform(mcdonalds['Gender'])\n",
    "Gender = mcdonalds.groupby('cluster_label')['Gender'].mean().reset_index()\n",
    "segment = Gender.merge(Like, on='cluster_label', how='left').merge(visit, on='cluster_label', how='left')\n",
    "segment\n",
    "plt.figure(figsize = (9,4))\n",
    "sns.scatterplot(x = \"VisitFrequency\", y = \"Like\",data=segment,s=1000, color=\"blue\")\n",
    "plt.title(\"Simple segment evaluation plot for the fast food mcdonalds set\",fontsize = 15)\n",
    "plt.xlabel(\"Visit\", fontsize = 14)\n",
    "plt.ylabel(\"Like\", fontsize = 14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "all",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
